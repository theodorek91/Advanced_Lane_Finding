{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import glob\n",
    "import pickle\n",
    "from moviepy.editor import VideoFileClip\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_val(y,poly_coeff):\n",
    "    return poly_coeff[0]*y**2+poly_coeff[1]*y+poly_coeff[2]\n",
    "    \n",
    "class Line:\n",
    "\n",
    "    \n",
    "    cache =defaultdict(list)\n",
    "    prev_left_lane_inds=[]\n",
    "    prev_right_lane_inds=[]\n",
    "    Line_detected = [False]\n",
    "    \n",
    "    def __init__(self, image, Frame):\n",
    "        self.img = image        \n",
    "        self.Frame = Frame\n",
    "        \n",
    "    \n",
    "    def set_detected(self,value):\n",
    "        self.Line_detected = True\n",
    "    \n",
    "    def get_frame_number(self):\n",
    "        return self.Frame\n",
    "    \n",
    "    def get_undistort(self, mtx,dist):\n",
    "        self.mtx=mtx\n",
    "        self.dist=dist\n",
    "        self.img2 = cv2.undistort(self.img, mtx, dist, None, mtx)\n",
    "        \n",
    "        #Apply ROI MASK\n",
    "        self.img2 = self.region_of_interest(self.img2,np.asarray([[[190,self.img2.shape[0]],[450,400],[700,420],[750 ,400],[1200,self.img2.shape[0]]]], dtype=np.int32))\n",
    "\n",
    "        return self.img2\n",
    "    def region_of_interest(self,img, vertices):\n",
    "        \"\"\"\n",
    "        Applies an image mask.\n",
    "\n",
    "        Only keeps the region of the image defined by the polygon\n",
    "        formed from `vertices`. The rest of the image is set to black.\n",
    "        \"\"\"\n",
    "        #defining a blank mask to start with\n",
    "        mask = np.zeros_like(img)   \n",
    "\n",
    "        #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "        if len(img.shape) > 2:\n",
    "            channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "            ignore_mask_color = (255,) * channel_count\n",
    "        else:\n",
    "            ignore_mask_color = 255\n",
    "\n",
    "        #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "        cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "\n",
    "        #returning the image only where mask pixels are nonzero\n",
    "        masked_image = cv2.bitwise_and(img, mask)\n",
    "        return masked_image\n",
    "    \n",
    "    def get_sobel_thresh(self, orient ='x'):\n",
    "        gray = cv2.cvtColor(self.img2,cv2.COLOR_BGR2GRAY)\n",
    "        sobel_kernel=3\n",
    "        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize = sobel_kernel)\n",
    "        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize = sobel_kernel)\n",
    "        abs_sobely = np.absolute(sobely)\n",
    "        abs_sobelx = np.absolute(sobelx)\n",
    "        scaled_sobelx= np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "        scaled_sobely = np.uint8(255*abs_sobely/np.max(abs_sobely))\n",
    "        sxbinary = np.zeros_like(scaled_sobelx)\n",
    "        sybinary = np.zeros_like(scaled_sobely)\n",
    "        thresh_min = 35\n",
    "        thresh_max = 150\n",
    "        sxbinary[(scaled_sobelx >= thresh_min) & (scaled_sobelx <= thresh_max)] = 1\n",
    "        sybinary[(scaled_sobely >= thresh_min) & (scaled_sobely <= thresh_max)] = 1\n",
    "        if orient == 'x':\n",
    "            return sxbinary, sobelx, sobely\n",
    "        if orient == 'y':\n",
    "            return sybinary, sobelx, sobely\n",
    "\n",
    "    def get_mag_thresh(self, sobel_kernel =3, mag_thresh_min= 20, mag_thresh_max =100, thresh_min=20, thresh_max=100):\n",
    "        [temp, sobelx, sobely] = self.get_sobel_thresh()\n",
    "        sobelxy = np.sqrt(sobelx**2,sobely**2)\n",
    "        scalefactor = np.max(sobelxy)/255\n",
    "        scaled_sobelxy = (sobelxy/scalefactor).astype(np.uint8) \n",
    "        sxbinary = np.zeros_like(scaled_sobelxy)\n",
    "        sxbinary[(scaled_sobelxy >= mag_thresh_min) & (scaled_sobelxy <= mag_thresh_max)] = 1\n",
    "        return sxbinary, sobelx, sobely\n",
    "    \n",
    "    def get_dir_threshold(self, sobel_kernel= 3):\n",
    "        [temp, sobelx,sobely ] = self.get_sobel_thresh('x')\n",
    "        absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "        binary_output =  np.zeros_like(absgraddir)\n",
    "        thresh=(0.8,1.08)\n",
    "        binary_output[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "        return binary_output\n",
    "\n",
    "    def get_hls_thresh(self):\n",
    "        hls = cv2.cvtColor(self.img2, cv2.COLOR_BGR2HLS)\n",
    "        S = hls[:,:,2]\n",
    "        L = hls[:,:,1]\n",
    "        threshL =(30,255)\n",
    "        threshS = (120, 255)\n",
    "        binary = np.zeros_like(S)\n",
    "        binary[((S > threshS[0]) & (S <= threshS[1]) )&((L > threshL[0]) & (L <= threshL[1]) )] = 1\n",
    "        return binary\n",
    "\n",
    "    def get_combine_thresholds(self):\n",
    "        self.get_undistort(self.mtx,self.dist)\n",
    "        [sx,temp1,temp2] = self.get_sobel_thresh('x')\n",
    "        [sy,temp1,temp2] = self.get_sobel_thresh('y')\n",
    "        [m_sx,temp1,temp2] = self.get_mag_thresh(3,30,255, 35, 150)\n",
    "        dir_bin = self.get_dir_threshold(3)\n",
    "        hls_bin = self.get_hls_thresh()\n",
    "        combined = np.zeros_like(dir_bin)\n",
    "        combined[(((sx == 1)) | ((m_sx == 1) & (dir_bin == 1)) | (hls_bin ==1))] = 1\n",
    "        return combined\n",
    "    \n",
    "    def get_p_transform(self,img):\n",
    "        img_size = (img.shape[1], img.shape[0])\n",
    "        src = np.float32(\n",
    "            [[200, 720],\n",
    "            [1100, 720],\n",
    "            [595, 460],\n",
    "            [685, 460]])\n",
    "        dst = np.float32(\n",
    "            [[300, 720],\n",
    "            [980, 720],\n",
    "            [300, 0],\n",
    "            [980, 0]])\n",
    "        self.m = cv2.getPerspectiveTransform(src, dst)\n",
    "        self.m_inv = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "        warped = cv2.warpPerspective(img, self.m, img_size, flags=cv2.INTER_LINEAR)\n",
    "        unwarped = cv2.warpPerspective(warped, self.m_inv, (warped.shape[1], warped.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "        return warped, unwarped, self.m, self.m_inv\n",
    "    \n",
    "       \n",
    "    def find_hist(self, temp, win_y_low = None, win_y_high = 520):\n",
    "        if win_y_low is None:\n",
    "            win_y_low = temp.shape[0]\n",
    "        else:\n",
    "            win_y_low=temp.shape[0]\n",
    "            win_y_high = 0\n",
    "\n",
    "        histogram = np.sum(temp[win_y_high:,:],axis=0)\n",
    "        return histogram\n",
    "    \n",
    "    def fit_poly(self,img, nwindows = 9, prev_base = None):\n",
    "        #plt.imshow(img)\n",
    "        try:\n",
    "            histogram = self.find_hist(img)\n",
    "            # Create an output image to draw on and  visualize the result\n",
    "            out_img = np.dstack((img, img, img))*255\n",
    "            # Find the peak of the left and right halves of the histogram\n",
    "            # These will be the starting point for the left and right lines\n",
    "            midpoint = np.int(histogram.shape[0]/2)\n",
    "            leftx_base = np.argmax(histogram[:midpoint])\n",
    "            rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "            # Choose the number of sliding windows\n",
    "            nwindows = 9\n",
    "            # Set height of windows\n",
    "            window_height = np.int(img.shape[0]/nwindows)\n",
    "            # Identify the x and y positions of all nonzero pixels in the image\n",
    "            nonzero = img.nonzero()\n",
    "            nonzeroy = np.array(nonzero[0])\n",
    "            nonzerox = np.array(nonzero[1])\n",
    "            # Current positions to be updated for each window\n",
    "            if (prev_base is None):\n",
    "                leftx_current = leftx_base\n",
    "                rightx_current = rightx_base\n",
    "\n",
    "\n",
    "                # Set the width of the windows +/- margin\n",
    "                margin = 100\n",
    "                # Set minimum number of pixels found to recenter window\n",
    "                minpix = 50\n",
    "                # Create empty lists to receive left and right lane pixel indices\n",
    "                left_lane_inds = []\n",
    "                right_lane_inds = []\n",
    "\n",
    "                # Step through the windows one by one\n",
    "                for window in range(nwindows):\n",
    "                    # Identify window boundaries in x and y (and right and left)\n",
    "                    win_y_low = img.shape[0] - (window+1)*window_height\n",
    "                    win_y_high = img.shape[0] - window*window_height\n",
    "                    win_xleft_low = leftx_current - margin\n",
    "                    win_xleft_high = leftx_current + margin\n",
    "                    win_xright_low = rightx_current - margin\n",
    "                    win_xright_high = rightx_current + margin\n",
    "                    # Draw the windows on the visualization image\n",
    "                    cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "                    cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "                    # Identify the nonzero pixels in x and y within the window\n",
    "                    good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "                    good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "                    # Append these indices to the lists\n",
    "                    left_lane_inds.append(good_left_inds)\n",
    "                    right_lane_inds.append(good_right_inds)\n",
    "                    # recenter next window on the last position\n",
    "                    try:\n",
    "                        leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "                        rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "                        #print(leftx_current)\n",
    "                    except:\n",
    "                        pass\n",
    "                # Concatenate the arrays of indices\n",
    "                left_lane_inds = np.concatenate(left_lane_inds)\n",
    "                right_lane_inds = np.concatenate(right_lane_inds)\n",
    "            else:\n",
    "                left_fit=prev_base[0]\n",
    "                right_fit=prev_base[1]\n",
    "                left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "                right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "\n",
    "            # Extract left and right line pixel positions\n",
    "            leftx = nonzerox[left_lane_inds]\n",
    "            lefty = nonzeroy[left_lane_inds] \n",
    "            rightx = nonzerox[right_lane_inds]\n",
    "            righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "            # Fit a second order polynomial to each\n",
    "            #if prev_base is None:\n",
    "                #print(len(lefty),len(leftx))\n",
    "            #else:\n",
    "                #print(len(lefty),len(leftx), len(prev_base))\n",
    "            left_fit = np.polyfit(lefty, leftx, 2)\n",
    "            right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "            ploty = np.linspace(0, img.shape[0]-1, img.shape[0] )\n",
    "            left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "            right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "            return [out_img, left_fitx,right_fitx, ploty] , [left_fit,right_fit], [left_lane_inds, right_lane_inds, nonzerox, nonzeroy], self.Line_detected\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def get_final_image(self,L1_Polyfit, L1_S_perspective):\n",
    "        # caluclate curvature and offset\n",
    "        left_rad, rightrad = self.get_lane_curvature(L1_Polyfit[2])\n",
    "        offset = self.get_offset(L1_Polyfit[1])\n",
    "        \n",
    "        left_line = np.hstack(((np.array([np.transpose(np.vstack([L1_Polyfit[0][1]+20, L1_Polyfit[0][3]]))])),(np.array([np.flipud(np.transpose(np.vstack([L1_Polyfit[0][1]-10, L1_Polyfit[0][3]])))]))))\n",
    "        right_line = np.hstack(((np.array([np.transpose(np.vstack([L1_Polyfit[0][2]+20, L1_Polyfit[0][3]]))])),(np.array([np.flipud(np.transpose(np.vstack([L1_Polyfit[0][2]-10, L1_Polyfit[0][3]])))]))))\n",
    "\n",
    "        window_leftEdge = np.array([np.transpose(np.vstack([L1_Polyfit[0][1], L1_Polyfit[0][3]]))])\n",
    "        window_rightEdge = np.array([np.flipud(np.transpose(np.vstack([L1_Polyfit[0][2], L1_Polyfit[0][3]])))])\n",
    "        windowPTs = np.hstack((window_leftEdge, window_rightEdge))\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_TRIPLEX\n",
    "        final_image=(np.dstack((L1_S_perspective[0], L1_S_perspective[0], L1_S_perspective[0]))*255).astype('uint8')\n",
    "        final_image=np.zeros(np.asarray(final_image).shape, np.uint8)\n",
    "        cv2.fillPoly(final_image, np.int_([windowPTs]), (0,255, 0))\n",
    "        cv2.fillPoly(final_image, np.int_([left_line]), (255,0, 0))\n",
    "        cv2.fillPoly(final_image, np.int_([right_line]), (255,0, 0))\n",
    "        cv2.putText(final_image, 'Radius:  ' + str(round((left_rad+rightrad)/2)) +'  m' ,(0,240),font, 1,(0,255,0))\n",
    "        cv2.putText(final_image, 'Offset:  ' + str(offset) +'  m' , (0,280),font,1,(0,255,0) )\n",
    "        \n",
    "\n",
    "        unwarped_f= cv2.warpPerspective(final_image, self.m_inv, (self.img.shape[1], self.img.shape[0]))\n",
    "        final =np.hstack((cv2.addWeighted(unwarped_f,0.5,self.img,1,0),L1_Polyfit[0][0]))\n",
    "        #plt.imshow(final)\n",
    "        return final\n",
    "        \n",
    "    def get_lane_curvature(self,lane_inds):\n",
    "        # Define conversions in x and y from pixels space to meters\n",
    "        ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "        xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "\n",
    "        nonzerox = lane_inds[2]\n",
    "        nonzeroy = lane_inds[3]\n",
    "        left_lane_inds = lane_inds[0]\n",
    "        right_lane_inds = lane_inds[1]\n",
    "\n",
    "        leftx = nonzerox[left_lane_inds]\n",
    "        lefty = nonzeroy[left_lane_inds] \n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "\n",
    "        y_eval = (self.img.shape[0]-1)\n",
    "        # Fit new polynomials to x,y in world space\n",
    "        left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "        right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "        # Calculate the new radii of curvature\n",
    "        left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "        right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "\n",
    "        return left_curverad, right_curverad\n",
    "    \n",
    "    \n",
    "    def get_offset(self,lane_inds):\n",
    "              \n",
    "        xm_per_pix = 3.7/700\n",
    "        image_center = self.img.shape[1]/2\n",
    "        \n",
    "        left_low = get_val(self.img.shape[0],lane_inds[0])\n",
    "        right_low = get_val(self.img.shape[0],lane_inds[1])\n",
    "        \n",
    "        # pixel coordinate for center of lane\n",
    "        lane_center = (left_low+right_low)/2.0\n",
    "    \n",
    "        ## vehicle offset\n",
    "        distance = image_center - lane_center\n",
    "\n",
    "        ## convert to metric\n",
    "        return (round(distance*xm_per_pix,5))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def second_pipeline(img):\n",
    "\n",
    "    global Frame\n",
    "    global cache\n",
    "    global Stack_Counter\n",
    "    \n",
    "    [mtx,dist] = pickle.load(open('Calib_Mat.p','rb'))\n",
    "    LineS_Image1 = Line(img,Frame)\n",
    "    L1_U=LineS_Image1.get_undistort(mtx,dist)\n",
    "    L1_S_combined = LineS_Image1.get_combine_thresholds()\n",
    "    L1_S_perspective = LineS_Image1.get_p_transform(L1_S_combined)\n",
    "    L1_Polyfit = LineS_Image1.fit_poly(L1_S_perspective[0],L1_S_perspective[1])\n",
    "    try:\n",
    "        detected = L1_Polyfit[3]\n",
    "        LineS_Image1.set_detected(detected)\n",
    "    except:\n",
    "        pass\n",
    "    final_image= LineS_Image1.get_final_image(L1_Polyfit,L1_S_perspective)\n",
    "\n",
    "    Frame+=1\n",
    "    return final_image\n",
    "\n",
    "    \n",
    "\n",
    "#return(np.hstack((cv2.cvtColor(img,cv2.COLOR_BGR2RGB),np.dstack((L1_S_perspective[0],L1_S_perspective[0], L1_S_perspective[0])))))\n",
    "#return np.hstack((cv2.cvtColor(img,cv2.COLOR_BGR2RGB),L1_Polyfit[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video Project_Video_Processed3.mp4\n",
      "[MoviePy] Writing video Project_Video_Processed3.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|████████████████████████████████████████▍ | 25/26 [00:09<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: Project_Video_Processed3.mp4 \n",
      "\n",
      "Wall time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "global Frame, cache, Stack_Counter\n",
    "Stack_Counter=1\n",
    "cache=defaultdict(list)\n",
    "Frame=1\n",
    "out='Project_Video_Processed.mp4'\n",
    "video=VideoFileClip('project_video.mp4').subclip(22,23)\n",
    "video_clip =video.fl_image(second_pipeline)\n",
    "%time video_clip.write_videofile(out, audio=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
